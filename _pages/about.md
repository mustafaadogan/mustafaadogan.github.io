---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Software Engineer at [Aselsan](https://www.aselsan.com/en) and a recent MSc graduate from [Hacettepe University’s Computer Engineering Department](https://cs.hacettepe.edu.tr/index.html), where I worked under the guidance of [Erkut Erdem](https://web.cs.hacettepe.edu.tr/~erkut/) and [Aykut Erdem](https://aykuterdem.github.io/). My research centers on natural language processing, with an emphasis on vision-language tasks and complex NLP problems. I am also involved in creating benchmarks and analysis tools, and I have a strong interest in foundation models. Previously, I earned my BSc from [Konya Food and Agriculture University](https://international.gidatarim.edu.tr/), where I collaborated with [Kasim Oztoprak](https://www.linkedin.com/in/kasim-oztoprak-b714bb190/?originalSubdomain=tr) on sentiment analysis and computer architecture education.

### **Publications**

<table style="width:100%;border:0;border-spacing:0;border-collapse:collapse;margin-right:auto;margin-left:auto;">
    <tr>
        <td style="padding:2.5%;width:100%;vertical-align:middle;border:0;">
            <h2 style="border-bottom:0px">2024</h2>
            <HR style="border-style:inset; border-width:1px;">
        </td>
    </tr>
</table>

<table style="border:0;border-spacing:0;border-collapse:collapse;">
    <tr>
        <td style="padding:10px;width:25%;vertical-align:middle;border:0;">
            <img src="images/icl_overview.png" alt="MLLM Evaluation Overview" width="160" height="120" style="border-style:none;">
        </td>
        <td style="width:75%;vertical-align:middle;border:0;">
            <a href="https://arxiv.org/abs/2407.12498">
                <span class="papertitle"><strong>Evaluating Linguistic Capabilities of Multimodal LLMs in the Lens of Few-Shot Learning</strong></span>
            </a>
            <br>
            <strong>Mustafa Dogan</strong>, Ilker Kesen, Iacer Calixto, Aykut Erdem, Erkut Erdem
            <br>
            <em>arXiv</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2407.12498">Paper</a>  
            / <a href="https://github.com/mustafaadogan/Few-Shot-MMLLM-Analysis">Code</a>
            <p>
                This study evaluates the performance of Multimodal Large Language Models (MLLMs) on the VALSE benchmark, highlighting the significant impact of few-shot In-Context Learning and Chain-of-Thought prompting on complex reasoning tasks, and underscores the influence of pretraining datasets in optimizing MLLMs for better grounding in visual contexts.
            </p>
        </td>
    </tr>
</table>

<table style="border:0;border-spacing:0;border-collapse:collapse;"> 
    <tr>
        <td style="padding:10px;width:25%;vertical-align:middle;border:0;">
            <img src="images/vilma.png" alt="ViLMA Benchmark Overview" width="160" height="120" style="border-style: none">
        </td>
        <td style="width:75%;vertical-align:middle;border:0;">
            <a href="https://cyberiada.github.io/ViLMA/" id="vilma">
                <span class="papertitle"><strong>ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models</strong></span>
            </a>
        <br>
        Ilker Kesen, Andrea Pedrotti, <strong>Mustafa Dogan</strong>, Michele Cafagna, Emre Can Acikgoz, Letitia Parcalabescu, Iacer Calixto, Anette Frank, Albert Gatt, Aykut Erdem, Erkut Erdem
        <br>
        <em>ICLR</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2311.07022">Paper</a> 
        / <a href=" https://cyberiada.github.io/ViLMA/">Website</a> 
        / <a href="https://github.com/ilkerkesen/ViLMA">Code</a>
        <p>This study introduces ViLMA (<strong>Vi</strong>deo <strong>L</strong>anguage <strong>M</strong>odel <strong>A</strong>ssessment), a task-agnostic benchmark designed to rigorously evaluate the fine-grained visio-linguistic capabilities of Video-Language Models, revealing that current models struggle with grounding abilities and perform similarly to static image-based models, particularly when evaluated with proficiency and counterfactual tests.</p>
        </td>
    </tr>
</table>



<table style="border:0;border-spacing:0;border-collapse:collapse;">
    <tr>
        <td style="padding:10px;width:25%;vertical-align:middle;border:0;">
            <img src="images/cpu_overview.png" alt="Block-Diagram of a Simple CPU" width="160" height="120" style="border-style:none;">
        </td>
        <td style="width:75%;vertical-align:middle;border:0;">
            <a href="https://peerj.com/articles/cs-1818/">
                <span class="papertitle"><strong>Teaching computer architecture by designing and simulating processors from their bits and bytes</strong></span>
            </a>
            <br>
            <strong>Mustafa Dogan</strong>, Kasim Oztoprak, Mehmet Resit Tolun
            <br>
            <em>PeerJ Computer Science</em>, 2024
            <br>
            <a href="https://peerj.com/articles/cs-1818/">Paper</a>
            / <a href="https://github.com/SevcanDogramaci/Processor-Simulator">MuSe Arc: Simulator Code</a>
            / <a href="https://github.com/omer-metin/CPU16-Simulator">DoMe Arc: Simulator Code</a>
            / <a href="https://github.com/SevcanDogramaci/Processor-Verilog-Simulation">MuSe Arc: Verilog Code</a>
            / <a href="https://github.com/mustafaadogan/RISC16-Verilog">DoMe Arc: Verilog Code</a>
            / <a href="https://www.youtube.com/playlist?list=PL9PP7AO6lwHfsfOVjCUsG72CyZtLYKFtx">YouTube Playlist</a>  
            <p>
                This article highlights how team-based, hands-on projects, including designing and implementing a 16-bit MIPS-like processor, significantly enhance student motivation and knowledge in computer architecture courses, even in the absence of lab components, by engaging them in practical design, simulation, and verification phases, and shows that peer interactions further deepen their understanding of custom processor design.
            </p>
        </td>
    </tr>
</table>


<table style="width:100%;border:0;border-spacing:0;border-collapse:collapse;margin-right:auto;margin-left:auto;">
    <tr>
        <td style="padding:2.5%;width:100%;vertical-align:middle;border:0;">
            <h2  style="border-bottom:0px">2020</h2>
            <HR style="border-style:inset; border-width:1px;">
        </td>
    </tr>
</table>

<table style="border:0;border-spacing:0;border-collapse:collapse;">
    <tr>
        <td style="padding:10px;width:25%;vertical-align:middle;border:0;">
            <img src="images/stock_market_evaluation_overview.png" alt="Tweet Evaluation Overview" width="160" height="120" style="border-style:none;">
        </td>
        <td style="width:75%;vertical-align:middle;border:0;">
            <a href="https://ieeexplore.ieee.org/document/9378170">
                <span class="papertitle"><strong>Speculator and Influencer Evaluation in Stock Market by Using Social Media</strong></span>
            </a>
            <br>
            <strong>Mustafa Dogan</strong>, Omer Metin, Elif Tek, Semih Yumusak, Kasim Oztoprak
            <br>
            <em>IEEE International Conference on Big Data</em>, 2020
            <br>
            <a href="https://ieeexplore.ieee.org/document/9378170">Paper</a>  
            / <a href="https://www.kaggle.com/datasets/omermetinn/tweets-about-the-top-companies-from-2015-to-2020">Dataset (Tweet)</a> 
            / <a href="https://www.kaggle.com/datasets/omermetinn/values-of-top-nasdaq-copanies-from-2010-to-2020">Dataset (Stock Market)</a> 
            <p>
                This study investigates possible speculators or influencers on Twitter who may manipulate stock prices of major NASDAQ companies like Google, Amazon, Apple, Tesla, and Microsoft, using sentiment analysis and machine learning models, revealing that noise reduction is essential for accurate correlation, tweet volume does not correlate with company volume, threshold impacts accuracy, and the RBF Kernel SVM method outperforms other algorithms.
            </p>
        </td>
    </tr>
</table>

### **Visits and Activities**

<table style="border:0;border-spacing:0;border-collapse:collapse;">
    <tr>
        <td style="padding:10px;width:25%;vertical-align:middle;border:0;">
            <img src="images/interstellar_inclusion.jpg" width="160" height="120" style="border-style:none;">
        </td>
        <td style="width:75%;vertical-align:middle;border:0;">
            <a href="/talks/2019-10-13-italy.html">
                <span class="papertitle"><strong>Erasmus+ Yout Exchange Project: Interstellar Inclusion</strong></span>
            </a>
            <br>
            <em>Perugia, Italy</em> - 2019
            <br>
            <a href="https://associazionekora.it/2020/06/11/youth-exchange-about-inclusion-and-astronomy/">Website</a>  
            / <a href="https://youtu.be/AoApSIrVOvg">YouTube Video</a> 
            <p>
                The "Interstellar Inclusion" Erasmus+ project brought together 36 young people from 6 countries to engage in a multicultural experience focused on fostering inclusivity, empathy, and intercultural awareness, using astronomy as a metaphorical framework to combat xenophobia and racism, promote European values, and empower participants through non-formal education activities such as team-building, intercultural nights, and interactive discussions.
            </p>
        </td>
    </tr>
</table>

<table style="border:0;border-spacing:0;border-collapse:collapse;">
    <tr>
        <td style="padding:10px;width:25%;vertical-align:middle;border:0;">
            <img src="images/usa_msu.jpeg" width="160" height="120" style="border-style:none;">
        </td>
        <td style="width:75%;vertical-align:middle;border:0;">
            <a href="/talks/2018-08-15-usa.html">
                <span class="papertitle"><strong>Visiting Sungeun Cho's Sensory Lab at Michigan State University</strong></span>
            </a>
            <br>
            <em>Michigan State University, USA</em> - 2018
            <br>
            <p>
                A multidisciplinary experience at <a href="https://agriculture.auburn.edu/about/directory/faculty/sungeun-cho/">Sungeun Cho</a>'s Sensory Lab, where I explored the relationship between sleeping patterns and eating habits using Python libraries, applied Bayes Theorem to evaluate test results, and gained valuable insights through collaboration, contributing to ongoing research and offering practical applications for partnering companies.
            </p>
        </td>
    </tr>
</table>

<table style="border:0;border-spacing:0;border-collapse:collapse;">
    <tr>
        <td style="padding:10px;width:25%;vertical-align:middle;border:0;">
            <img src="images/estonia.jpeg" width="160" height="120" style="border-style:none;">
        </td>
        <td style="width:75%;vertical-align:middle;border:0;">
            <a href="/talks/2018-06-01-estonia.html">
                <span class="papertitle"><strong>Erasmus+ Yout Exchange Project: Sail With EntrepreneurShip</strong></span>
            </a>
            <br>
            <em>Nelijärve, Estonia</em> - 2018
            <br>
            <a href="https://erasmus-plus.ec.europa.eu/projects/search/details/2017-3-EE01-KA105-046776">Website</a>  
            <p>
                The "Sail With EntrepreneurShip" youth exchange, held in Tallinn, Estonia, from May 24th to June 1st, 2018, empowered 36 participants from seven countries in social entrepreneurship. The project focused on developing skills in creative thinking, financial management, and strategic planning through hands-on activities like role-plays and business model workshops. It aimed to tackle youth unemployment by equipping young people with practical tools to drive social change.
            </p>
        </td>
    </tr>
</table>
